import { useCallback, useEffect, useState, useRef } from "react";
import Button from '@/components/buttons/Button';
import { useAppContext } from "@/context/AppContext";
import { faTrash, faUpload } from "@fortawesome/free-solid-svg-icons";
import { FontAwesomeIcon } from "@fortawesome/react-fontawesome";
import { faCamera } from "@fortawesome/free-solid-svg-icons";

const ProfilePicture = ({ init, id, onChange, currentImage, ...props }) => {
    const [ready, setReady] = useState(false);
    const [dragActive, setDragActive] = useState(false);
    const [preview, setPreview] = useState(currentImage || null);
    const [isCapturing, setIsCapturing] = useState(false);
    const [stream, setStream] = useState(null);
    const [faceInPosition, setFaceInPosition] = useState(false);
    const [facePositionReady, setFacePositionReady] = useState(false);
    const [positionInstructions, setPositionInstructions] = useState('Posicione seu rosto na moldura');
    const [cameraLoading, setCameraLoading] = useState(false);
    const [photoFromCamera, setPhotoFromCamera] = useState(false); // Novo estado para diferenciar origem da foto

    // Estados para MediaPipe (preservar inst√¢ncia EXATAMENTE como photo-modal.js)
    const [mediaPipeReady, setMediaPipeReady] = useState(false);
    const [mediaPipeErrorCount, setMediaPipeErrorCount] = useState(0);
    const [isMonitoringStarted, setIsMonitoringStarted] = useState(false);
    const [isDetectingFace, setIsDetectingFace] = useState(false);
    const [isInitializingMediaPipe, setIsInitializingMediaPipe] = useState(false);
    const [mediaPipeInitAttempts, setMediaPipeInitAttempts] = useState(0);

    const { user, toast } = useAppContext();

    const fileInputRef = useRef(null);
    const videoRef = useRef(null);
    const canvasRef = useRef(null);
    const positionCheckRef = useRef(null);

    // Refs para MediaPipe (preservar inst√¢ncia)
    const faceDetectionRef = useRef(null);
    const mediaPipeCameraRef = useRef(null);
    const mediaPipeCallbackReceived = useRef(false);

    // Constantes MediaPipe - EXATO como photo-modal.js
    const MAX_MEDIAPIPE_ERRORS = 5;
    const MAX_MEDIAPIPE_ATTEMPTS = 5;

    useEffect(() => {
        if (currentImage) {
            setPreview(currentImage);
            setPhotoFromCamera(false); // Imagem atual n√£o √© da c√¢mera
        }
    }, [currentImage]);

    // Cleanup camera stream on unmount
    useEffect(() => {
        return () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            if (positionCheckRef.current) {
                clearInterval(positionCheckRef.current);
            }
            // Limpar MediaPipe apenas com limpeza suave (preservar inst√¢ncia)
            cleanupMediaPipe();
        };
    }, [stream]);

    // Fun√ß√£o para limpeza suave do MediaPipe (preservar inst√¢ncia)
    const cleanupMediaPipe = () => {
        console.log('üßπ Limpeza suave do MediaPipe (preservando inst√¢ncia)...');

        // Parar c√¢mera MediaPipe, mas NUNCA destruir faceDetection
        if (mediaPipeCameraRef.current) {
            console.log('üõë Parando camera MediaPipe...');
            mediaPipeCameraRef.current.stop();
            mediaPipeCameraRef.current = null;
        }

        // JAMAIS fechar faceDetection - sempre preservar
        console.log('üîí Inst√¢ncia do MediaPipe PERMANENTEMENTE preservada');

        console.log('‚úÖ Limpeza suave MediaPipe conclu√≠da - inst√¢ncia preservada');
    };

    // Verificar suporte a MediaPipe Face Detection - C√ìPIA EXATA do photo-modal.js
    const checkMediaPipeSupport = async () => {
        console.log('üîç Verificando MediaPipe Face Detection...');

        // SEMPRE tentar usar MediaPipe se dispon√≠vel (NUNCA desabilitar permanentemente)
        console.log('üîÑ MediaPipe NUNCA √© desabilitado permanentemente');

        // PRIORIDADE: Se MediaPipe j√° est√° funcionando, SEMPRE reutilizar
        if (mediaPipeReady && faceDetectionRef.current) {
            console.log('‚ôªÔ∏è MediaPipe J√Å FUNCIONA - reutilizando inst√¢ncia existente (ZERO recria√ß√£o)');
            console.log('üìä Estado da inst√¢ncia:', {
                mediaPipeReady,
                faceDetection: !!faceDetectionRef.current,
                errorCount: mediaPipeErrorCount
            });
            return true;
        }

        console.log('üîç Inicializando nova inst√¢ncia MediaPipe...');
        console.log('üåê User Agent:', navigator.userAgent.substring(0, 100));
        console.log('üåê Navigator.mediaDevices dispon√≠vel:', !!navigator.mediaDevices);

        // Evitar m√∫ltiplas inicializa√ß√µes simult√¢neas
        if (isInitializingMediaPipe) {
            console.log('‚è≥ MediaPipe j√° est√° sendo inicializado...');
            return mediaPipeReady;
        }

        // Verificar tentativas m√°ximas
        if (mediaPipeInitAttempts >= MAX_MEDIAPIPE_ATTEMPTS) {
            console.log('‚ùå M√°ximo de tentativas MediaPipe atingido, usando fallback');
            return await checkNativeFaceDetection();
        }

        setIsInitializingMediaPipe(true);
        setMediaPipeInitAttempts(prev => prev + 1);

        try {
            // N√ÉO limpar inst√¢ncias anteriores - apenas verificar se j√° existe
            if (faceDetectionRef.current) {
                console.log('‚ôªÔ∏è Inst√¢ncia MediaPipe j√° existe, validando...');
                // Verificar se a inst√¢ncia ainda est√° funcionando
                if (mediaPipeReady) {
                    console.log('‚úÖ Inst√¢ncia MediaPipe v√°lida, reutilizando');
                    setIsInitializingMediaPipe(false);
                    return true;
                }
            }

            // Verificar se MediaPipe est√° dispon√≠vel
            if (typeof window !== 'undefined' && typeof window.FaceDetection !== 'undefined') {
                console.log('‚úÖ MediaPipe FaceDetection detectado!');

                // Criar inst√¢ncia com timeout
                const initSuccess = await new Promise((resolve, reject) => {
                    const timeout = setTimeout(() => {
                        reject(new Error('Timeout na inicializa√ß√£o do MediaPipe'));
                    }, 3000);

                    try {
                        const faceDetection = new window.FaceDetection({
                            locateFile: (file) => {
                                return `https://cdn.jsdelivr.net/npm/@mediapipe/face_detection/${file}`;
                            }
                        });

                        faceDetection.setOptions({
                            model: 'short',
                            minDetectionConfidence: 0.05, // Ainda mais baixo para detectar faces distantes
                        });

                        console.log('‚öôÔ∏è MediaPipe configurado com minDetectionConfidence: 0.05 (faces distantes)');

                        // Criar callback wrapper com logs detalhados e prote√ß√£o de erro - EXATO como photo-modal.js
                        faceDetection.onResults(function (results) {
                            try {
                                console.log('üéØ MediaPipe onResults DIRETO:', {
                                    detections: results.detections?.length || 0,
                                    hasImage: !!results.image,
                                    timestamp: Date.now() - (window.startTime || Date.now())
                                });

                                // Contador de callbacks recebidos
                                window.mediaPipeCallbackCount = (window.mediaPipeCallbackCount || 0) + 1;
                                console.log('üìä Total de callbacks MediaPipe recebidos:', window.mediaPipeCallbackCount);

                                // Chamar fun√ß√£o principal com prote√ß√£o
                                onFaceDetectionResults(results);

                            } catch (callbackError) {
                                console.error('‚ùå Erro no callback wrapper MediaPipe:', callbackError);
                                // N√ÉO chamar handleMediaPipeError aqui para evitar loop
                                // Apenas logar o erro e continuar
                            }
                        });

                        // Salvar inst√¢ncia e marcar como pronto
                        faceDetectionRef.current = faceDetection;
                        setMediaPipeReady(true);
                        setIsInitializingMediaPipe(false);

                        clearTimeout(timeout);
                        console.log('‚úÖ MediaPipe Face Detection inicializado - Modo MEDIAPIPE ativado');
                        resolve(true);

                    } catch (error) {
                        clearTimeout(timeout);
                        reject(error);
                    }
                });

                return initSuccess;

            } else {
                throw new Error('MediaPipe n√£o encontrado');
            }

        } catch (error) {
            console.warn(`‚ùå Erro MediaPipe (tentativa ${mediaPipeInitAttempts}/${MAX_MEDIAPIPE_ATTEMPTS}):`, error.message);
            console.log('üìä Detalhes do erro:', {
                errorName: error.name,
                errorMessage: error.message,
                userAgent: navigator.userAgent.substring(0, 100),
                mediaPipeAvailable: typeof window.FaceDetection !== 'undefined'
            });

            cleanupMediaPipe();
            setIsInitializingMediaPipe(false);

            // Tentar novamente ou usar fallback
            if (mediaPipeInitAttempts < MAX_MEDIAPIPE_ATTEMPTS) {
                const waitTime = mediaPipeInitAttempts * 1500; // Delay progressivo: 1.5s, 3s, 4.5s...
                console.log(`üîÑ Tentando novamente em ${waitTime}ms... (tentativa ${mediaPipeInitAttempts + 1}/${MAX_MEDIAPIPE_ATTEMPTS})`);
                await new Promise(resolve => setTimeout(resolve, waitTime));
                return await checkMediaPipeSupport();
            } else {
                console.log('üîÑ Todas as tentativas MediaPipe esgotadas, usando fallback nativo...');
                return await checkNativeFaceDetection();
            }
        }
    };

    // Fun√ß√£o auxiliar para tentar Face Detection API nativa - EXATO do photo-modal.js
    const checkNativeFaceDetection = async () => {
        try {
            if ('FaceDetector' in window) {
                console.log('‚úÖ Face Detection API nativa detectada!');
                const faceDetector = new FaceDetector({
                    maxDetectedFaces: 1,
                    fastMode: true
                });
                console.log('‚úÖ FaceDetector criado com sucesso');
                return true;
            } else {
                console.log('‚ùå Face Detection API n√£o suportada, usando simula√ß√£o');
                return true; // Usar simula√ß√£o
            }
        } catch (error) {
            console.warn('‚ùå Erro na detec√ß√£o nativa:', error);
            return true; // Usar simula√ß√£o como √∫ltimo recurso
        }
    };

    // Callback para resultados do MediaPipe - EXATO do photo-modal.js (fun√ß√£o normal, n√£o useCallback)
    const onFaceDetectionResults = (results) => {
        try {
            window.mediaPipeCallbackReceived = true; // Marcar que callback foi recebido

            console.log('üîç onFaceDetectionResults chamado:', {
                isDetectingFace: mediaPipeCallbackReceived.current, // Usar ref em vez de state
                detectionsCount: results.detections?.length || 0,
                timestamp: Date.now(),
                hasImage: !!results.image,
                imageWidth: results.image?.width,
                imageHeight: results.image?.height
            });

            // Validar se results existe e tem estrutura esperada
            if (!results || typeof results !== 'object') {
                console.warn('‚ö†Ô∏è Results inv√°lido ou inexistente');
                return;
            }

            // Log detalhado dos resultados
            if (results.detections && Array.isArray(results.detections) && results.detections.length > 0) {
                console.log('üéØ Detec√ß√µes encontradas:', results.detections.map(d => ({
                    score: d.score,
                    boundingBox: d.boundingBox
                })));
            }

            // Usar ref em vez de state para verifica√ß√£o
            if (!mediaPipeCallbackReceived.current) {
                console.log('‚èπÔ∏è mediaPipeCallbackReceived.current √© false, retornando');
                return;
            }

            // Continuar com a l√≥gica principal...
            processDetectionResults(results);

        } catch (error) {
            console.error('‚ùå Erro em onFaceDetectionResults:', error);
            console.log('üîß Continuando execu√ß√£o sem parar v√≠deo...');
            // N√ÉO fazer fallback aqui - apenas logar e continuar
        }
    };

    // Processar resultados de detec√ß√£o - EXATO do photo-modal.js
    const processDetectionResults = (results) => {
        try {
            console.log(`üîç PROCESSANDO RESULTADOS: ${results.detections?.length || 0} rosto(s) detectado(s)`);

            if (results.detections && Array.isArray(results.detections) && results.detections.length > 0) {
                const detection = results.detections[0];

                let bbox = detection.locationData?.relativeBoundingBox;

                // Verificar estruturas alternativas do MediaPipe
                if (!bbox && detection.boundingBox) {
                    bbox = detection.boundingBox;
                }

                if (!bbox) {
                    console.warn('‚ö†Ô∏è bbox inv√°lido, usando simula√ß√£o');
                    handleMediaPipeError();
                    return;
                }

                // Verificar posicionamento
                const centerX = bbox.xCenter || (bbox.x + bbox.width / 2);
                const centerY = bbox.yCenter || (bbox.y + bbox.height / 2);
                const idealCenterX = 0.5;
                const idealCenterY = 0.5;

                // Toler√¢ncia para posicionamento
                const tolerance = 0.15;
                const isWellPositioned =
                    Math.abs(centerX - idealCenterX) <= tolerance &&
                    Math.abs(centerY - idealCenterY) <= tolerance;

                console.log('üìç Posicionamento:', {
                    centerX: centerX.toFixed(3),
                    centerY: centerY.toFixed(3),
                    isWellPositioned,
                    bbox
                });

                setFaceInPosition(isWellPositioned);
                setFacePositionReady(true);

                if (isWellPositioned) {
                    setPositionInstructions('‚úÖ Perfeito! Rosto bem posicionado - clique para capturar');
                } else {
                    if (centerX < idealCenterX - tolerance) {
                        setPositionInstructions('‚Üê Mova um pouco para a direita');
                    } else if (centerX > idealCenterX + tolerance) {
                        setPositionInstructions('‚Üí Mova um pouco para a esquerda');
                    } else if (centerY < idealCenterY - tolerance) {
                        setPositionInstructions('‚Üì Mova um pouco para baixo');
                    } else if (centerY > idealCenterY + tolerance) {
                        setPositionInstructions('‚Üë Mova um pouco para cima');
                    }
                }

            } else {
                console.log('üë§ Nenhum rosto detectado');
                setFaceInPosition(false);
                setFacePositionReady(false);
                setPositionInstructions('üë§ Posicione seu rosto dentro da moldura');
            }

        } catch (error) {
            console.error('‚ùå Erro processando resultados:', error);
            handleMediaPipeError();
        }
    };

    // Tratar erros do MediaPipe - EXATO do photo-modal.js
    const handleMediaPipeError = () => {
        console.log('üîß handleMediaPipeError: iniciando fallback para simula√ß√£o');

        // Simular detec√ß√£o positiva para permitir captura
        setFaceInPosition(true);
        setFacePositionReady(true);
        setPositionInstructions('‚ú® Modo simula√ß√£o ativo - clique em "Capturar Foto" quando estiver pronto');

        console.log('‚úÖ Simula√ß√£o de detec√ß√£o facial ativa');
    };

    // Processar resultados do MediaPipe
    const processMediaPipeResults = (results) => {
        try {
            console.log(`ÔøΩ PROCESSANDO MEDIAPIPE: ${results.detections?.length || 0} rosto(s) detectado(s)`);

            if (results.detections && Array.isArray(results.detections) && results.detections.length > 0) {
                const detection = results.detections[0];

                let bbox = detection.locationData?.relativeBoundingBox;

                // Verificar estruturas alternativas do MediaPipe
                if (!bbox && detection.boundingBox) {
                    bbox = detection.boundingBox;
                }

                if (!bbox) {
                    console.warn('‚ö†Ô∏è MediaPipe bbox inv√°lido, usando fallback');
                    handleMediaPipeError();
                    return;
                }

                // Verificar posicionamento
                const centerX = bbox.xCenter;
                const centerY = bbox.yCenter;
                const idealCenterX = 0.5;
                const idealCenterY = 0.5;

                // Toler√¢ncia para posicionamento
                const toleranceX = 0.25;
                const toleranceY = 0.25;

                // Verificar tamanho do rosto
                const faceSize = bbox.width * bbox.height;
                const idealSize = 0.06;
                const sizeRatio = faceSize / idealSize;

                const distanceX = Math.abs(centerX - idealCenterX);
                const distanceY = Math.abs(centerY - idealCenterY);

                const confidence = detection.score && detection.score[0] ? detection.score[0] : 0.5;

                console.log('üìê MediaPipe m√©tricas:', {
                    centerX: centerX.toFixed(2),
                    centerY: centerY.toFixed(2),
                    sizeRatio: sizeRatio.toFixed(2),
                    confidence: Math.round(confidence * 100) + '%'
                });

                if (distanceX <= toleranceX && distanceY <= toleranceY &&
                    sizeRatio >= 0.2 && sizeRatio <= 4.0 && confidence > 0.05) {
                    // Rosto bem posicionado
                    console.log('‚úÖ MediaPipe: ROSTO BEM POSICIONADO');
                    setFaceInPosition(true);
                    setFacePositionReady(true);
                    setPositionInstructions('‚úÖ Perfeito! Rosto detectado - Clique para capturar');
                } else if (sizeRatio < 0.2) {
                    setFaceInPosition(false);
                    setFacePositionReady(true);
                    setPositionInstructions('üìè Pode chegar um pouco mais perto da c√¢mera');
                } else if (sizeRatio > 4.0) {
                    setFaceInPosition(false);
                    setFacePositionReady(true);
                    setPositionInstructions('üìè Afaste-se um pouco da c√¢mera');
                } else {
                    setFaceInPosition(false);
                    setFacePositionReady(true);
                    setPositionInstructions('‚ÜîÔ∏è Centralize seu rosto na moldura');
                }
            } else {
                // Nenhum rosto detectado
                console.log('‚ùå MediaPipe: NENHUM ROSTO DETECTADO');
                setFaceInPosition(false);
                setFacePositionReady(false);
                setPositionInstructions('üë§ Posicione seu rosto dentro da moldura');
            }

        } catch (error) {
            console.error('‚ùå Erro em processMediaPipeResults:', error);
        }
    };

    // Iniciar detec√ß√£o nativa Face Detection API - EXATO do photo-modal.js
    const startNativeFaceDetection = async () => {
        try {
            console.log('üîß startNativeFaceDetection: iniciando Face Detection API nativa');

            if ('FaceDetector' in window) {
                console.log('‚úÖ Face Detection API dispon√≠vel!');

                const faceDetector = new FaceDetector({
                    maxDetectedFaces: 1,
                    fastMode: true
                });

                // Simular detec√ß√£o com an√°lise de pixels b√°sica
                setFaceDetectionMethod('native');
                console.log('üéØ Face Detection API ativa');

                // Para simplificar, usar simula√ß√£o direta
                startSimulatedFaceDetection();

            } else {
                console.log('‚ùå Face Detection API n√£o suportada, usando simula√ß√£o');
                startSimulatedFaceDetection();
            }

        } catch (error) {
            console.warn('‚ùå Erro na detec√ß√£o nativa:', error);
            startSimulatedFaceDetection();
        }
    };

    // Iniciar simula√ß√£o de detec√ß√£o facial - EXATO do photo-modal.js
    const startSimulatedFaceDetection = () => {
        console.log('üé≠ startSimulatedFaceDetection: iniciando simula√ß√£o');
        setFaceDetectionMethod('simulation');

        // Simular detec√ß√£o positiva para permitir captura
        setFacePosition({
            detected: true,
            wellPositioned: true,
            message: 'Simula√ß√£o ativa - posicione seu rosto e clique para capturar'
        });

        setFaceInPosition(true);
        setFacePositionReady(true);
        setPositionInstructions('‚ú® Modo simula√ß√£o ativo - clique em "Capturar Foto" quando estiver pronto');

        console.log('‚úÖ Simula√ß√£o de detec√ß√£o facial ativa');
    };

    // Fun√ß√£o para detectar rosto em arquivo de imagem
    const detectFaceInFile = async (file) => {
        console.log('üîç Iniciando detec√ß√£o facial no arquivo:', file.name);

        try {
            // M√©todo 1: Tentar MediaPipe primeiro (mais preciso)
            if (mediaPipeReady && faceDetectionRef.current) {
                console.log('üî¨ Usando MediaPipe para detec√ß√£o facial...');
                const result = await detectFaceWithMediaPipe(file);
                if (result !== null) {
                    console.log('‚úÖ MediaPipe detectou:', result ? 'rosto encontrado' : 'nenhum rosto');
                    return result;
                }
            }

            // M√©todo 2: Face Detection API nativa
            if ('FaceDetector' in window) {
                console.log('üîç Usando Face Detection API nativa...');

                // Criar uma imagem a partir do arquivo
                const imageBitmap = await createImageBitmap(file);

                // Configura√ß√£o otimizada para detec√ß√£o
                const faceDetector = new FaceDetector({
                    maxDetectedFaces: 10, // Aumentado para detectar mais rostos
                    fastMode: false       // Modo mais preciso
                });

                // Detectar rostos
                const faces = await faceDetector.detect(imageBitmap);

                console.log(`üë• Face Detection API: ${faces.length} rosto(s) detectado(s)`);

                // Analisar qualidade dos rostos detectados
                if (faces.length > 0) {
                    const faceQuality = analyzeFaceQuality(faces, imageBitmap);
                    console.log('üìä Qualidade dos rostos:', faceQuality);

                    // Considerar rosto v√°lido se houver pelo menos um com qualidade aceit√°vel
                    return faceQuality.hasGoodQuality;
                }

                return false;

            } else {
                console.log('‚ö†Ô∏è Face Detection API n√£o dispon√≠vel');
            }

            // M√©todo 3: An√°lise b√°sica de pixel (fallback)
            console.log('üé≠ Usando an√°lise b√°sica de pixels como fallback...');
            const hasBasicFaceFeatures = await analyzeImageForFaceFeatures(file);
            console.log('üîç An√°lise b√°sica detectou caracter√≠sticas faciais:', hasBasicFaceFeatures);

            return hasBasicFaceFeatures;

        } catch (error) {
            console.error('‚ùå Erro na detec√ß√£o facial:', error);

            // Em caso de erro, usar an√°lise de fallback mais simples
            try {
                console.log('üîß Tentando fallback simples...');
                const basicAnalysis = await analyzeImageBasic(file);
                return basicAnalysis;
            } catch (fallbackError) {
                console.error('‚ùå Erro no fallback:', fallbackError);
                // Se tudo falhar, retornar true para n√£o bloquear o usu√°rio
                return true;
            }
        }
    };

    // Fun√ß√£o auxiliar para detectar rosto com MediaPipe
    const detectFaceWithMediaPipe = async (file) => {
        try {
            // Criar elemento de imagem tempor√°rio
            const img = new Image();
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');

            return new Promise((resolve) => {
                img.onload = async function () {
                    canvas.width = img.width;
                    canvas.height = img.height;
                    ctx.drawImage(img, 0, 0);

                    // Processar com MediaPipe
                    try {
                        await faceDetectionRef.current.send({ image: canvas });

                        // MediaPipe vai chamar onFaceDetectionResults
                        // Vamos aguardar um tempo para o resultado
                        setTimeout(() => {
                            // Verificar se houve detec√ß√£o recente
                            const hasRecentDetection = checkRecentFaceDetection();
                            resolve(hasRecentDetection);
                        }, 1000);

                    } catch (error) {
                        console.error('Erro MediaPipe:', error);
                        resolve(null); // Indica falha, tentar pr√≥ximo m√©todo
                    }
                };

                img.onerror = () => resolve(null);
                img.src = URL.createObjectURL(file);
            });

        } catch (error) {
            console.error('Erro na prepara√ß√£o MediaPipe:', error);
            return null;
        }
    };

    // Fun√ß√£o para analisar qualidade dos rostos detectados
    const analyzeFaceQuality = (faces, imageBitmap) => {
        let hasGoodQuality = false;
        const imageArea = imageBitmap.width * imageBitmap.height;

        for (const face of faces) {
            const bbox = face.boundingBox;
            const faceArea = bbox.width * bbox.height;
            const faceRatio = faceArea / imageArea;

            // Considerar rosto com qualidade boa se:
            // - Ocupa pelo menos 5% da imagem (n√£o muito pequeno)
            // - N√£o ocupa mais de 80% da imagem (n√£o muito pr√≥ximo)
            // - Tem propor√ß√µes razo√°veis (altura/largura entre 1.2 e 2.0)
            const aspectRatio = bbox.height / bbox.width;

            if (faceRatio >= 0.05 && faceRatio <= 0.8 && aspectRatio >= 1.0 && aspectRatio <= 2.0) {
                hasGoodQuality = true;
                console.log('‚úÖ Rosto com boa qualidade encontrado:', {
                    area: `${(faceRatio * 100).toFixed(1)}%`,
                    aspect: aspectRatio.toFixed(2)
                });
                break;
            }
        }

        return {
            hasGoodQuality,
            totalFaces: faces.length,
            facesData: faces.map(face => ({
                area: ((face.boundingBox.width * face.boundingBox.height) / imageArea * 100).toFixed(1) + '%',
                aspect: (face.boundingBox.height / face.boundingBox.width).toFixed(2)
            }))
        };
    };

    // Fun√ß√£o para an√°lise b√°sica de caracter√≠sticas faciais
    const analyzeImageForFaceFeatures = async (file) => {
        try {
            const imageBitmap = await createImageBitmap(file);
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');

            // Redimensionar para an√°lise (otimiza√ß√£o)
            const maxSize = 200;
            let { width, height } = imageBitmap;

            if (width > maxSize || height > maxSize) {
                const ratio = Math.min(maxSize / width, maxSize / height);
                width = width * ratio;
                height = height * ratio;
            }

            canvas.width = width;
            canvas.height = height;
            ctx.drawImage(imageBitmap, 0, 0, width, height);

            const imageData = ctx.getImageData(0, 0, width, height);
            const data = imageData.data;

            // An√°lise b√°sica: procurar regi√µes de tons de pele e contrastes
            let skinTonePixels = 0;
            let contrastAreas = 0;
            const totalPixels = data.length / 4;

            for (let i = 0; i < data.length; i += 4) {
                const r = data[i];
                const g = data[i + 1];
                const b = data[i + 2];

                // Detectar tons de pele (aproxima√ß√£o b√°sica)
                if (isSkinTone(r, g, b)) {
                    skinTonePixels++;
                }

                // Detectar √°reas de contraste (poss√≠veis caracter√≠sticas faciais)
                if (i + 4 < data.length) {
                    const nextR = data[i + 4];
                    if (Math.abs(r - nextR) > 30) {
                        contrastAreas++;
                    }
                }
            }

            const skinRatio = skinTonePixels / totalPixels;
            const contrastRatio = contrastAreas / totalPixels;

            // Heur√≠stica: se h√° uma porcentagem razo√°vel de tons de pele e contraste
            const hasFaceFeatures = skinRatio > 0.1 && contrastRatio > 0.05;

            console.log('üìä An√°lise b√°sica:', {
                skinRatio: (skinRatio * 100).toFixed(1) + '%',
                contrastRatio: (contrastRatio * 100).toFixed(1) + '%',
                result: hasFaceFeatures
            });

            return hasFaceFeatures;

        } catch (error) {
            console.error('Erro na an√°lise b√°sica:', error);
            return false;
        }
    };

    // Fun√ß√£o auxiliar para detectar tons de pele
    const isSkinTone = (r, g, b) => {
        // Algoritmo simples para detectar tons de pele
        // Baseado em: https://en.wikipedia.org/wiki/Human_skin_color
        return (
            r > 95 && g > 40 && b > 20 &&
            Math.max(r, g, b) - Math.min(r, g, b) > 15 &&
            Math.abs(r - g) > 15 && r > g && r > b
        ) || (
                r > 220 && g > 210 && b > 170 &&
                Math.abs(r - g) <= 15 && r > b && g > b
            );
    };

    // Fun√ß√£o de fallback mais simples
    const analyzeImageBasic = async (file) => {
        try {
            // Verifica√ß√£o b√°sica: se √© uma imagem v√°lida e tem tamanho razo√°vel
            const imageBitmap = await createImageBitmap(file);

            // Se conseguiu criar imageBitmap e tem dimens√µes razo√°veis
            const isValidImage = imageBitmap.width >= 50 && imageBitmap.height >= 50;
            console.log('üîç An√°lise b√°sica simples:', isValidImage);

            return isValidImage;

        } catch (error) {
            console.error('Erro na an√°lise b√°sica simples:', error);
            return false;
        }
    };

    // Fun√ß√£o para verificar detec√ß√£o recente do MediaPipe
    const checkRecentFaceDetection = () => {
        // Esta fun√ß√£o deveria verificar se houve detec√ß√£o facial recente
        // Por simplicidade, retorna true (pode ser melhorada)
        return true;
    };

    const handleFileSelect = async (file) => {
        if (!file) return;

        // Prote√ß√£o contra execu√ß√£o m√∫ltipla
        if (window.isProcessingProfileFile) {
            console.log('‚ö†Ô∏è J√° processando um arquivo, ignorando...');
            return;
        }

        window.isProcessingProfileFile = true;

        try {
            console.log('üìÅ Processando arquivo:', file.name, file.size, 'bytes');

            // Valida√ß√£o de tipo
            if (!file.type.startsWith('image/')) {
                toast.error('Por favor, selecione apenas arquivos de imagem');
                return;
            }

            // Valida√ß√£o de tamanho (3MB)
            if (file.size > 3 * 1024 * 1024) {
                toast.error('Imagem muito grande. M√°ximo permitido: 3MB');
                return;
            }

            console.log('üîç Iniciando valida√ß√£o de detec√ß√£o facial...');

            // Mostrar loading de valida√ß√£o
            toast.info('üîç Verificando se h√° rosto detect√°vel na imagem...');

            try {
                // Realizar detec√ß√£o facial
                const faceDetected = await detectFaceInFile(file);

                if (faceDetected) {
                    console.log('‚úÖ Rosto detectado com sucesso!');
                    toast.success('‚úÖ Rosto detectado com sucesso!');
                } else {
                    console.log('‚ö†Ô∏è Nenhum rosto detectado');

                    // Usar confirm do navegador para compatibilidade
                    const confirmUpload = window.confirm(
                        '‚ö†Ô∏è Nenhum rosto foi detectado na imagem.\n\n' +
                        'Para melhor reconhecimento facial, recomendamos:\n' +
                        '‚Ä¢ Foto com rosto bem vis√≠vel e centralizado\n' +
                        '‚Ä¢ Boa ilumina√ß√£o no rosto\n' +
                        '‚Ä¢ Pessoa olhando para a c√¢mera\n' +
                        '‚Ä¢ Rosto ocupando pelo menos 30% da imagem\n\n' +
                        'Deseja continuar mesmo assim?'
                    );

                    if (!confirmUpload) {
                        console.log('‚ùå Usu√°rio cancelou upload');
                        return;
                    }

                    console.log('‚ö†Ô∏è Usu√°rio optou por continuar sem rosto detectado');
                }

            } catch (error) {
                console.error('‚ùå Erro na valida√ß√£o facial:', error);

                const confirmUpload = window.confirm(
                    '‚ö†Ô∏è N√£o foi poss√≠vel verificar se h√° um rosto na imagem.\n\n' +
                    'Deseja continuar mesmo assim?'
                );

                if (!confirmUpload) {
                    return;
                }
            }

            // Criar preview
            const reader = new FileReader();
            reader.onload = (e) => {
                setPreview(e.target.result);
                setPhotoFromCamera(false); // Marcar como arquivo selecionado, n√£o da c√¢mera
            };
            reader.readAsDataURL(file);

            // Chamar callback para o componente pai
            if (typeof onChange === 'function') {
                onChange('ds_foto_candidato', file);
            }

            console.log('‚úÖ Arquivo processado com sucesso');

        } finally {
            // Sempre liberar o lock ap√≥s um tempo
            setTimeout(() => {
                window.isProcessingProfileFile = false;
            }, 1000);
        }
    };

    const handleFileInputChange = (evt) => {
        const file = evt.target.files[0];
        handleFileSelect(file);
    };

    // Drag and Drop handlers
    const handleDrag = useCallback((e) => {
        e.preventDefault();
        e.stopPropagation();
        if (e.type === "dragenter" || e.type === "dragover") {
            setDragActive(true);
        } else if (e.type === "dragleave") {
            setDragActive(false);
        }
    }, []);

    const handleDrop = useCallback((e) => {
        e.preventDefault();
        e.stopPropagation();
        setDragActive(false);

        if (e.dataTransfer.files && e.dataTransfer.files[0]) {
            handleFileSelect(e.dataTransfer.files[0]);
        }
    }, []);

    // Face position detection functions - EXATAMENTE como photo-modal.js
    const startFacePositionMonitoring = async () => {
        // Verificar se j√° est√° rodando
        if (isMonitoringStarted) {
            console.log('‚è∏Ô∏è Monitoramento j√° est√° ativo, ignorando nova chamada');
            return;
        }

        console.log('üé• Iniciando monitoramento de posi√ß√£o facial...');
        setIsMonitoringStarted(true);

        // Limpar detec√ß√£o anterior se existir
        if (isDetectingFace) {
            console.log('üõë Parando detec√ß√£o anterior...');
            stopFacePositionMonitoring();
            await new Promise(resolve => setTimeout(resolve, 300));
        }

        // Ativar detec√ß√£o - definir flag como ativa
        setIsDetectingFace(true);
        mediaPipeCallbackReceived.current = true; // Ativar callback
        console.log('üî¥ isDetectingFace e callback flag definidos como true');

        // Verificar suporte MediaPipe com a mesma l√≥gica do photo-modal.js
        const hasMediaPipe = await checkMediaPipeSupport();

        if (hasMediaPipe) {
            console.log('üöÄ Iniciando detec√ß√£o facial MEDIAPIPE');
            await startMediaPipeFaceDetection();
        } else {
            console.log('üöÄ Iniciando detec√ß√£o facial NATIVA/FALLBACK');
            startNativeFaceDetection();
        }
    };

    // Iniciar detec√ß√£o MediaPipe - EXATAMENTE como no photo-modal.js
    const startMediaPipeFaceDetection = async () => {
        if (!videoRef.current || !faceDetectionRef.current) {
            console.error('‚ùå Video ou FaceDetection n√£o dispon√≠vel');
            handleMediaPipeError();
            return;
        }

        const video = videoRef.current;
        console.log('üì∏ Iniciando MediaPipe com v√≠deo:', video.videoWidth, 'x', video.videoHeight);

        try {
            // IMPORTANTE: Limpar c√¢mera anterior APENAS se existir
            if (mediaPipeCameraRef.current) {
                try {
                    console.log('üõë Parando c√¢mera MediaPipe anterior...');
                    mediaPipeCameraRef.current.stop();
                } catch (e) {
                    console.warn('‚ö†Ô∏è Erro ao parar c√¢mera anterior:', e);
                }
                mediaPipeCameraRef.current = null;
            }

            // Aguardar um pouco para garantir limpeza
            await new Promise(resolve => setTimeout(resolve, 200));

            // Verificar se v√≠deo est√° pronto
            if (video.readyState < 2) {
                console.log('‚è≥ Aguardando v√≠deo ficar pronto...');
                await new Promise((resolve) => {
                    const timeout = setTimeout(resolve, 2000); // Timeout de seguran√ßa
                    video.addEventListener('canplay', () => {
                        clearTimeout(timeout);
                        resolve();
                    }, { once: true });
                });
            }

            // Inicializar nova c√¢mera do MediaPipe - REUTILIZANDO a inst√¢ncia existente
            console.log('üé¨ Criando nova Camera MediaPipe (preservando FaceDetection)...');
            const camera = new window.Camera(video, {
                onFrame: async () => {
                    // Verifica√ß√£o simples e direta - apenas se callback est√° ativo
                    if (!mediaPipeCallbackReceived.current) {
                        return;
                    }

                    try {
                        if (!video || video.readyState < 2) return;
                        if (video.videoWidth === 0 || video.videoHeight === 0) return;

                        // NUNCA recriar faceDetection - sempre usar a inst√¢ncia preservada
                        await faceDetectionRef.current.send({ image: video });

                    } catch (frameError) {
                        console.error('‚ùå Erro no frame MediaPipe:', frameError);

                        // Detectar erro WASM cr√≠tico
                        if (frameError.message.includes('Module.arguments') ||
                            frameError.message.includes('Aborted') ||
                            frameError.message.includes('WASM') ||
                            frameError.message.includes('unreachable')) {

                            console.warn('‚ö†Ô∏è Erro WASM cr√≠tico detectado!');
                            handleMediaPipeError();
                            return;
                        }

                        // Incrementar contador de erros
                        setMediaPipeErrorCount(prev => prev + 1);
                    }
                },
                width: 640,
                height: 480
            });

            console.log('‚ñ∂Ô∏è Iniciando camera MediaPipe...');
            await camera.start();
            mediaPipeCameraRef.current = camera;
            console.log('‚úÖ C√¢mera MediaPipe iniciada com sucesso (inst√¢ncia FaceDetection preservada)');

            // Teste de timeout para verificar funcionamento (reduzi para 2 segundos)
            setTimeout(() => {
                if (mediaPipeCallbackReceived.current) {
                    console.log('‚úÖ MediaPipe funcionando - callbacks sendo processados');
                } else {
                    console.warn('‚ö†Ô∏è MediaPipe sem callbacks em 2 segundos, verificando...');
                    // MediaPipe pode estar funcionando mesmo sem receber callback ainda
                    // Apenas logar, n√£o usar fallback imediatamente
                }
            }, 2000);

        } catch (error) {
            console.error('‚ùå Erro ao inicializar Camera MediaPipe:', error);
            handleMediaPipeError();
        }
    };

    // REMOVIDO: Detec√ß√£o nativa melhorada (duplicada - usando vers√£o do photo-modal.js)
    /*
    const startNativeFaceDetection = () => {
        if (positionCheckRef.current) {
            clearInterval(positionCheckRef.current);
        }

        // Verificar se o navegador suporta Face Detection API
        const hasFaceDetection = 'FaceDetector' in window;
        console.log('Face Detection API dispon√≠vel:', hasFaceDetection);

        if (hasFaceDetection) {
            detectFaceWithAPI();
        } else {
            detectFaceWithPixelAnalysis();
        }

        positionCheckRef.current = setInterval(() => {
            if (!isDetectingFace) return;

            if (hasFaceDetection) {
                detectFaceWithAPI();
            } else {
                detectFaceWithPixelAnalysis();
            }
        }, 500);
    };

    // Detec√ß√£o usando Face Detection API nativa
    const detectFaceWithAPI = async () => {
        if (!videoRef.current || !canvasRef.current) return;

        try {
            const video = videoRef.current;
            const canvas = canvasRef.current;
            const ctx = canvas.getContext('2d', { willReadFrequently: true });

            // Configurar canvas
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            // Desenhar frame atual
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Criar detector de rosto
            const faceDetector = new FaceDetector({
                maxDetectedFaces: 1,
                fastMode: true
            });

            // Detectar rostos no canvas
            const faces = await faceDetector.detect(canvas);

            if (faces.length > 0) {
                const face = faces[0];
                const faceBox = face.boundingBox;

                // Calcular centro do rosto
                const faceCenterX = faceBox.x + faceBox.width / 2;
                const faceCenterY = faceBox.y + faceBox.height / 2;

                // √Årea ideal para o rosto (centro da tela)
                const idealCenterX = canvas.width / 2;
                const idealCenterY = canvas.height / 2;

                // Calcular dist√¢ncia do centro ideal
                const distanceX = Math.abs(faceCenterX - idealCenterX);
                const distanceY = Math.abs(faceCenterY - idealCenterY);

                // Toler√¢ncia para posicionamento (em pixels)
                const toleranceX = canvas.width * 0.15; // 15% da largura
                const toleranceY = canvas.height * 0.15; // 15% da altura

                // Verificar tamanho do rosto (muito pequeno = longe, muito grande = perto)
                const faceSize = faceBox.width * faceBox.height;
                const idealSize = (canvas.width * 0.3) * (canvas.height * 0.4); // 30% x 40% da tela
                const sizeRatio = faceSize / idealSize;

                if (distanceX <= toleranceX && distanceY <= toleranceY &&
                    sizeRatio >= 0.5 && sizeRatio <= 2.0) {
                    // Rosto bem posicionado
                    setFaceInPosition(true);
                    setFacePositionReady(true);
                    setPositionInstructions('‚úÖ Perfeito! Rosto detectado e bem posicionado');
                } else if (sizeRatio < 0.5) {
                    // Muito longe
                    setFaceInPosition(false);
                    setFacePositionReady(true);
                    setPositionInstructions('üìè Chegue mais perto da c√¢mera');
                } else if (sizeRatio > 2.0) {
                    // Muito perto
                    setFaceInPosition(false);
                    setFacePositionReady(true);
                    setPositionInstructions('üìè Afaste-se um pouco da c√¢mera');
                } else {
                    // Fora de posi√ß√£o
                    setFaceInPosition(false);
                    setFacePositionReady(true);
                    setPositionInstructions('‚ÜîÔ∏è Centralize seu rosto na moldura');
                }
            } else {
                // Nenhum rosto detectado
                setFaceInPosition(false);
                setFacePositionReady(false);
                setPositionInstructions('üë§ Posicione seu rosto na moldura');
            }
        } catch (error) {
            console.warn('Erro na Face Detection API:', error);
            // Fallback para an√°lise de pixels
            detectFaceWithPixelAnalysis();
        }
    };
    */

    // Detec√ß√£o usando an√°lise inteligente de pixels (fallback)
    const detectFaceWithPixelAnalysis = () => {
        if (!videoRef.current || !canvasRef.current) return;

        const video = videoRef.current;
        const canvas = canvasRef.current;
        const ctx = canvas.getContext('2d', { willReadFrequently: true });

        // Configurar canvas
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Desenhar frame atual
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

        // Obter dados da imagem
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const data = imageData.data;

        // Analisar regi√£o central onde esperamos o rosto
        const centerX = Math.floor(canvas.width / 2);
        const centerY = Math.floor(canvas.height / 2);
        const faceRegionSize = Math.min(canvas.width, canvas.height) * 0.3;

        let skinPixels = 0;
        let totalPixels = 0;
        let brightnessSum = 0;
        let contrastAreas = 0;

        // Verificar regi√£o facial em grid
        for (let y = centerY - faceRegionSize / 2; y < centerY + faceRegionSize / 2; y += 8) {
            for (let x = centerX - faceRegionSize / 2; x < centerX + faceRegionSize / 2; x += 8) {
                if (x >= 0 && x < canvas.width && y >= 0 && y < canvas.height) {
                    const idx = (Math.floor(y) * canvas.width + Math.floor(x)) * 4;
                    const r = data[idx];
                    const g = data[idx + 1];
                    const b = data[idx + 2];

                    // Detectar tons de pele (rough skin detection)
                    const isSkinTone = (
                        r > 95 && g > 40 && b > 20 &&
                        r > g && r > b &&
                        Math.abs(r - g) > 15 &&
                        Math.max(r, g, b) - Math.min(r, g, b) > 15
                    );

                    if (isSkinTone) skinPixels++;

                    const brightness = (r + g + b) / 3;
                    brightnessSum += brightness;

                    // Detectar contraste (indicativo de caracter√≠sticas faciais)
                    if (brightness < 80 || brightness > 180) {
                        contrastAreas++;
                    }

                    totalPixels++;
                }
            }
        }

        const skinRatio = skinPixels / totalPixels;
        const avgBrightness = brightnessSum / totalPixels;
        const contrastRatio = contrastAreas / totalPixels;

        // L√≥gica de detec√ß√£o baseada em caracter√≠sticas faciais
        if (skinRatio > 0.15 && avgBrightness > 60 && avgBrightness < 200 && contrastRatio > 0.1) {
            // An√°lise mais detalhada para posicionamento
            if (skinRatio > 0.25 && contrastRatio > 0.15) {
                setFaceInPosition(true);
                setFacePositionReady(true);
                setPositionInstructions('‚úÖ Rosto detectado! Clique para capturar');
            } else {
                setFaceInPosition(false);
                setFacePositionReady(true);
                setPositionInstructions('üìç Ajuste sua posi√ß√£o na moldura');
            }
        } else if (skinRatio > 0.05) {
            // Rosto parcialmente detectado
            setFaceInPosition(false);
            setFacePositionReady(true);
            setPositionInstructions('üëÄ Mantenha seu rosto na moldura');
        } else {
            // Nenhum rosto detectado
            setFaceInPosition(false);
            setFacePositionReady(false);
            setPositionInstructions('üë§ Posicione seu rosto na moldura');
        }
    };

    const stopFacePositionMonitoring = () => {
        console.log('üõë Parando monitoramento facial...');

        // Resetar flags
        setIsDetectingFace(false);
        setIsMonitoringStarted(false);
        mediaPipeCallbackReceived.current = false; // Desativar callback
        console.log('üîÑ Flags de detec√ß√£o e callback desativadas');

        if (positionCheckRef.current) {
            clearInterval(positionCheckRef.current);
            positionCheckRef.current = null;
        }

        // Limpar c√¢mera MediaPipe mas preservar inst√¢ncia
        cleanupMediaPipe();

        console.log('‚úÖ Monitoramento facial parado');
    };

    // Camera handlers - vers√£o melhorada baseada no photo-modal.js
    const startCamera = async () => {
        console.log('üìπ Iniciando c√¢mera...');
        setCameraLoading(true);

        // SEMPRE resetar flags de monitoramento para nova sess√£o
        setIsMonitoringStarted(false);
        setIsDetectingFace(false);
        console.log('üîÑ Flags de monitoramento resetadas para nova sess√£o');

        // N√ÉO resetar contadores se MediaPipe j√° estiver funcionando (como photo-modal.js)
        if (!mediaPipeReady || !faceDetectionRef.current) {
            console.log('üîÑ Primeiro uso - permitindo nova inicializa√ß√£o MediaPipe');
        } else {
            console.log('üîí MediaPipe j√° funciona - mantendo inst√¢ncia existente');
        }

        // Resetar callback flag
        mediaPipeCallbackReceived.current = false;
        console.log('üîÑ Callback flag resetado para nova sess√£o');

        try {
            // Configura√ß√£o de c√¢mera
            const constraints = {
                video: {
                    width: { ideal: 640 },
                    height: { ideal: 480 },
                    facingMode: 'user'
                },
                audio: false
            };

            console.log('Solicitando getUserMedia...');
            const mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
            console.log('Stream obtido com sucesso:', mediaStream);

            setStream(mediaStream);
            setIsCapturing(true);

            // Aguardar o pr√≥ximo ciclo de renderiza√ß√£o para o video estar dispon√≠vel
            setTimeout(() => {
                if (videoRef.current) {
                    console.log('Configurando v√≠deo...');
                    const video = videoRef.current;

                    video.srcObject = mediaStream;

                    // Timeout de seguran√ßa
                    const safetyTimeout = setTimeout(() => {
                        console.log('Timeout de seguran√ßa - removendo loading');
                        setCameraLoading(false);
                    }, 8000);

                    // Quando o v√≠deo estiver pronto
                    const onCanPlay = () => {
                        console.log('V√≠deo pronto para reproduzir');
                        clearTimeout(safetyTimeout);
                        setCameraLoading(false);

                        // Aguardar estabiliza√ß√£o antes de iniciar detec√ß√£o
                        setTimeout(() => {
                            console.log('üéØ Iniciando detec√ß√£o facial ap√≥s v√≠deo estabilizar...');
                            startFacePositionMonitoring();
                        }, 500); // Reduzido para ser mais responsivo
                    };

                    const onLoadedMetadata = () => {
                        console.log('Metadata carregada - dimens√µes:', video.videoWidth, 'x', video.videoHeight);
                    };

                    video.addEventListener('canplay', onCanPlay, { once: true });
                    video.addEventListener('loadedmetadata', onLoadedMetadata, { once: true });

                    console.log('Event listeners adicionados, chamando play()...');

                    // Tentar reproduzir
                    video.play()
                        .then(() => {
                            console.log('V√≠deo reproduzindo com sucesso');
                        })
                        .catch(err => {
                            console.warn('Erro no play, mas continuando:', err);
                        });
                } else {
                    console.error('videoRef.current ainda √© null ap√≥s timeout!');
                    setCameraLoading(false);
                }
            }, 100);
        } catch (error) {
            console.error('Erro ao acessar c√¢mera:', error);
            setCameraLoading(false);

            let errorMessage = 'N√£o foi poss√≠vel acessar a c√¢mera.';

            if (error.name === 'NotAllowedError') {
                errorMessage = 'Acesso √† c√¢mera foi negado. Permita o acesso e tente novamente.';
            } else if (error.name === 'NotFoundError') {
                errorMessage = 'Nenhuma c√¢mera encontrada.';
            }

            toast.error(errorMessage);
        }
    };

    const stopCamera = () => {
        console.log('üìπ Parando c√¢mera...');

        // Resetar flags de detec√ß√£o PRIMEIRO
        setIsDetectingFace(false);
        setIsMonitoringStarted(false);
        console.log('üîÑ Flags de detec√ß√£o resetadas em stopCamera');

        // Parar monitoramento de rosto
        stopFacePositionMonitoring();

        // Parar o stream
        if (stream) {
            stream.getTracks().forEach(track => {
                track.stop();
                console.log('Track parado:', track.kind);
            });
            setStream(null);
        }

        // Limpar o v√≠deo
        if (videoRef.current) {
            videoRef.current.srcObject = null;
        }

        // Resetar estados
        setIsCapturing(false);
        setCameraLoading(false);
        setFaceInPosition(false);
        setFacePositionReady(false);
        setPositionInstructions('Posicione seu rosto na moldura');

        console.log('‚úÖ C√¢mera parada com sucesso');
    };

    const capturePhoto = async () => {
        if (!videoRef.current || !canvasRef.current) return;

        console.log('üì∑ Iniciando captura de foto...');

        const canvas = canvasRef.current;
        const video = videoRef.current;
        const context = canvas.getContext('2d', { willReadFrequently: true });

        // Dimensoes para foto quadrada 1:1 (avatar)
        const size = 512; // Tamanho final da imagem quadrada
        canvas.width = size;
        canvas.height = size;

        // Calcular area para captura centralizada do rosto
        const videoAspect = video.videoWidth / video.videoHeight;

        // Determinar dimens√µes de captura baseadas na √°rea da moldura
        let sourceSize, sourceX, sourceY;

        if (videoAspect > 1) {
            // V√≠deo mais largo - usar altura como refer√™ncia
            sourceSize = video.videoHeight * 0.8; // 80% da altura do v√≠deo
            sourceX = (video.videoWidth - sourceSize) / 2;
            sourceY = video.videoHeight * 0.1; // 10% do topo
        } else {
            // V√≠deo mais alto - usar largura como refer√™ncia
            sourceSize = video.videoWidth * 0.8; // 80% da largura do v√≠deo
            sourceX = video.videoWidth * 0.1; // 10% da esquerda
            sourceY = (video.videoHeight - sourceSize) / 2;
        }

        // Preencher fundo branco (evitar transparencia)
        context.fillStyle = '#ffffff';
        context.fillRect(0, 0, size, size);

        // Desenhar imagem do v√≠deo como quadrado inteiro (sem recorte circular)
        context.drawImage(
            video,
            sourceX, sourceY, sourceSize, sourceSize, // √°rea de origem (quadrada)
            0, 0, size, size                          // Destino (quadrado)
        );

        // Converter para blob com alta qualidade
        canvas.toBlob(async (blob) => {
            if (blob) {
                const file = new File([blob], 'profile-photo.jpg', {
                    type: 'image/jpeg',
                    lastModified: Date.now()
                });

                console.log('üì∏ Foto capturada, iniciando valida√ß√£o facial...');

                try {
                    // Validar se h√° rosto na foto capturada
                    const hasFace = await detectFaceInFile(file);

                    if (!hasFace) {
                        // Rosto n√£o detectado - perguntar se quer continuar
                        const continuar = window.confirm(
                            'N√£o foi poss√≠vel detectar um rosto nesta foto. ' +
                            'Para melhor qualidade, recomendamos capturar novamente com o rosto bem posicionado na moldura.\n\n' +
                            'Deseja manter esta foto mesmo assim?'
                        );

                        if (!continuar) {
                            // Usu√°rio quer tentar novamente
                            console.log('‚ùå Usu√°rio optou por tentar novamente');
                            return;
                        }
                    }

                    console.log('‚úÖ Foto validada, processando...');

                } catch (error) {
                    console.error('‚ùå Erro na valida√ß√£o da foto capturada:', error);
                    // Em caso de erro, continuar normalmente
                }

                // Continuar com o fluxo normal (com ou sem rosto detectado)
                handleFileSelect(file);
                setPhotoFromCamera(true); // Marcar como foto da c√¢mera
                stopCamera();
            }
        }, 'image/jpeg', 0.95);
    };

    const clearImage = () => {
        setPreview(null);
        setPhotoFromCamera(false); // Resetar origem da foto
        if (fileInputRef.current) {
            fileInputRef.current.value = '';
        }
        if (typeof onChange === 'function') {
            onChange('ds_foto_candidato', null);
        }
    };

    useEffect(() => {
        if (!init) {
            stopCamera();
            clearImage();
        }
    }, [init]);

    return (
        <div className="space-y-4 h-full">
            {/* Preview da imagem atual */}
            {preview && !isCapturing && (
                <div className="flex flex-col items-center space-y-4 h-full pt-16">
                    <div className="relative mx-auto">
                        <img
                            src={preview}
                            alt="Profile preview"
                            className="w-[256px] h-[256px] rounded-full object-cover border-4 border-gray-200"
                        />
                    </div>

                    {/* Bot√µes de a√ß√£o do preview */}
                    <div className="flex space-x-3">
                        {photoFromCamera ? (
                            // Mostrar "Tirar novamente" apenas se a foto veio da c√¢mera
                            <Button
                                buttonType="secondary"
                                onClick={startCamera}
                                className="flex items-center space-x-2"
                            >
                                <FontAwesomeIcon icon={faCamera} width="14" height="14" className="" />
                                <span>Tirar novamente</span>
                            </Button>
                        ) : (
                            // Mostrar "Selecionar outro" se a foto veio de arquivo
                            <Button
                                buttonType="secondary"
                                onClick={() => fileInputRef.current?.click()}
                                className="flex items-center space-x-2"
                            >
                                <FontAwesomeIcon icon={faUpload} width="14" height="14" className="" />
                                <span>Selecionar outro</span>
                            </Button>
                        )}
                        <Button
                            buttonType="secondary"
                            onClick={startCamera}
                            className="flex items-center space-x-2"
                        >
                            <FontAwesomeIcon icon={faCamera} width="14" height="14" className="" />
                            <span>Tirar foto</span>
                        </Button>
                        <Button
                            outline
                            buttonType="danger"
                            onClick={clearImage}
                            className="flex items-center space-x-2"
                        >
                            <FontAwesomeIcon icon={faTrash} width="14" height="14" />
                            <span>Remover</span>
                        </Button>
                    </div>
                </div>
            )}

            {/* √Årea de drag and drop */}
            {!isCapturing && !preview && (
                <div
                    className={`border-2 border-dashed rounded-lg p-8 text-center transition-all duration-300 cursor-pointer ${dragActive
                            ? 'border-blue-500 bg-blue-50 scale-105'
                            : 'border-gray-300 hover:border-gray-400 hover:bg-gray-50'
                        }`}
                    onDragEnter={handleDrag}
                    onDragLeave={handleDrag}
                    onDragOver={handleDrag}
                    onDrop={handleDrop}
                    onClick={() => fileInputRef.current?.click()}
                >
                    <div className="space-y-3">
                        <div className="mx-auto w-16 h-16 text-gray-400">
                            <svg fill="none" stroke="currentColor" viewBox="0 0 48 48" className="w-full h-full">
                                <path d="M28 8H12a4 4 0 00-4 4v20m32-12v8m0 0v8a4 4 0 01-4 4H12a4 4 0 01-4-4v-4m32-4l-3.172-3.172a4 4 0 00-5.656 0L28 28M8 32l9.172-9.172a4 4 0 015.656 0L28 28m0 0l4 4m4-24h8m-4-4v8m-12 4h.02" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round" />
                            </svg>
                        </div>
                        <div className="text-sm text-gray-600">
                            <span className="font-medium text-blue-600 hover:text-blue-500">
                                Clique para selecionar
                            </span>
                            {' '}ou arraste e solte uma imagem
                        </div>
                        <p className="text-xs text-gray-500">
                            PNG, JPG at√© 3MB
                        </p>
                    </div>
                </div>
            )}

            {/* Controles de c√¢mera */}
            {isCapturing ? (
                <div className="space-y-4 h-full">
                    <div className="relative rounded-lg overflow-hidden m-auto max-w-[300px] max-h-[300px] w-[300px] h-[300px]">
                        {cameraLoading && (
                            <div className="absolute inset-0  flex items-center justify-center z-10">
                                <div className="text-white text-center">
                                    <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-white mx-auto mb-4"></div>
                                    <p className="mb-4">Carregando c√¢mera...</p>
                                    <button
                                        onClick={() => {
                                            console.log('For√ßando sa√≠da do loading...');
                                            setCameraLoading(false);
                                        }}
                                        className="text-xs bg-white bg-opacity-20 px-3 py-1 rounded hover:bg-opacity-30"
                                    >
                                        Continuar mesmo assim
                                    </button>
                                </div>
                            </div>
                        )}

                        <video
                            ref={videoRef}
                            autoPlay
                            playsInline
                            muted
                            controls={false}
                            className="w-full h-full object-cover max-w-[300px] max-h-[300px] bg-black"
                            onLoadedMetadata={(e) => {
                                console.log('Video onLoadedMetadata:', e.target.videoWidth, e.target.videoHeight);
                            }}
                            onCanPlay={() => {
                                console.log('Video onCanPlay disparado');
                            }}
                            onPlaying={() => {
                                console.log('Video onPlaying disparado');
                            }}
                            onError={(e) => {
                                console.error('Video onError:', e);
                                setCameraLoading(false);
                                toast.error('Erro no elemento de v√≠deo');
                            }}
                            onLoadStart={() => {
                                console.log('Video onLoadStart');
                            }}
                        />

                        {/* Moldura facial oval - mais intuitiva para rostos */}
                        {!cameraLoading && (
                            <div className="absolute inset-0 flex items-center justify-center pointer-events-none">
                                <div
                                    className={`w-48 h-60 border-4 transition-colors rounded-full scale-y-125 ${faceInPosition ? 'border-green-500' : // ready - verde
                                            facePositionReady ? 'border-yellow-500' : // adjusting - amarelo
                                                'border-red-400' // positioning - vermelho
                                        }`}
                                >
                                    <div
                                        className="w-full h-full border-2 border-dashed border-current opacity-50 rounded-full"
                                    ></div>
                                </div>
                            </div>
                        )}

                        {/* Instru√ß√µes de posicionamento baseadas no photo-modal.js */}
                        {!cameraLoading && (
                            <div className={`
                                absolute bottom-4 left-1/2 transform -translate-x-1/2 px-4 py-2 rounded-lg text-white text-sm font-medium transition-colors
                                ${faceInPosition ? 'bg-green-600 bg-opacity-90' : facePositionReady ? 'bg-yellow-600 bg-opacity-90' : 'bg-red-600 bg-opacity-90'}`}
                            >
                                {positionInstructions}
                            </div>
                        )}

                        <canvas ref={canvasRef} className="hidden" />
                    </div>

                    <div className="flex justify-center space-x-3 h-fit">
                        <Button
                            buttonType="danger"
                            outline
                            onClick={stopCamera}
                            className="px-6 py-2"
                        >
                            Cancelar
                        </Button>
                        <Button
                            buttonType={"primary"}
                            onClick={capturePhoto}
                            disabled={!faceInPosition}
                            className={`flex justify-center px-6 py-2 rounded-lg font-medium transition-colors ${faceInPosition
                                    ? ''
                                    : 'cursor-not-allowed'
                                }`}
                        >
                            <FontAwesomeIcon icon={faCamera} width="16" height="16" className="mr-2"/>
                            Capturar
                        </Button>
                    </div>
                </div>
            ) : (
                /* Bot√µes de a√ß√£o */
                !preview && (
                    <div className="flex justify-center space-x-3">
                        <Button
                            buttonType="primary"
                            onClick={startCamera}
                            className="flex items-center"
                        >
                            <FontAwesomeIcon icon={faCamera} width="16" height="16" className="mr-2"/>
                            Tirar foto
                        </Button>
                    </div>
                )
            )}

            {/* Input file sempre dispon√≠vel (hidden) */}
            <input
                ref={fileInputRef}
                type="file"
                accept="image/png,image/jpg,image/jpeg"
                onChange={handleFileInputChange}
                className="hidden"
            />
        </div>
    );
};

export default ProfilePicture;